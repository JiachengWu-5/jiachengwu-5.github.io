---
layout: post
title: Daily Paper (2022.12.30 - 2023.1.3)
categories: [Daily Paper]
description: Some new papers
keywords: Computer Vision, Model
---
## 2022

### [1230_Rethinking Person Re-Identification via Semantic-Based Pretraining](https://arxiv.org/pdf/2110.05074.pdf)

- The pretraining in the ImageNet may not the wonderful solution for the re-identification task because of the intrinsic domain gap. This paper constructed **a FineGPR-C caption dataset** to improve the semantic pretraining task for Re-ID. Besides, **VirTex Based Re-ID pretraining approach named VTBR** is proposed. This method effectively improve the performance of supervised/unsupervised pretraining on ImageNet in some images. The reason maybe the pictures have some occlusion and multiple persons in the queries. The better performance reveals that **semantic pretraining method can capture global context information and more discriminative parts.**
- FineGPR-C caption dataset is generated using dynamic caption generating strategy. The example of the dataset is shown below. What's more, **Refined Selecting (RS) stradegy** was arose to decrease the redundancy among the different attributes in FineGPR-C. (RS improves performance about 1%-5% in the comparison tests.)

![FineGPR-C](/images/DailyPaper/01/1.png "FineGPR-C")

- VTBR adapted ResNet-50 and semantic backbone transformer in the framework, the details of VTBR is shown below. The visualization of VTBR method and other methods are shown below. It is clearly shown that the semantic information participate the Re-ID task.
  
![VTBR](/images/DailyPaper/01/2.png "VTBR")

![Visualization](/images/DailyPaper/01/3.png "(a)Original images (b)CNN-based pretraining method on ImageNet (c)Semantic-based VTBR method on FineGPR-C caption dataset Visualization of Attention Map")


### [1231_Dual encoder network with transformer-CNN for multi-organ segmentation](https://link-springer-com.lib.ezproxy.hkust.edu.hk/article/10.1007/s11517-022-02723-9)

- This paper proposes **a dual encoder network with transformer-CNN for multi-organ segmentation**. This network is the decoder-encoder U-net architecture. CNN and transformer encoder are combined to extracted the information of images. This is efficient and the fusion module can suppress the overfitting problem.
- The architecture of the method is shown below. **ResNet50** is the backbond of CNN encoder and **swin-transformer** is the backbone of transformer encoder. Spatial and channel attention are considered in the swin-transformer, so more details can be obtained in the fusion modules. Information loss problem could be alleviated. Besides, this method could be applied in other diseases. The visualization of test results on the ACDC dataset is shown below.
  
![Architecture](/images/DailyPaper/01/4.png "The Architecture of the Method")

![Visualization](/images/DailyPaper/01/5.png "Visualization of Test Results on the ACDC Dataset")

### [1231_Application of Convolutional Dendrite Net for Detection of Myocardial Infarction Using ECG Signals](https://ieeexplore.ieee.org/document/9954400/) 

- This paper proposes **CDD (Convolutional Dendrite Net)** which is based on the improved DD to  recognize the ECG signals. The structure of CDD is shown below. The main purpose is to improve the accuracy of Myocardial Infarction (MI) detection. Besides, Hilbert curve is used to encoder ECG signals belonging to 1-D tensor into image signals. Hilbert curve is regarded as a surjection from (0, 1) to region(0, 1) Ã— (0, 1). The ECG signal and the signal encoded by Hilbert curve is shown below.

![CDD Net](/images/DailyPaper/01/6.jpeg "The CDD Network Structure")

![Visualization of Signal](/images/DailyPaper/01/7.jpeg "(a) Original ECG signal (b)ECG signal after artifact removal (c)ECG signal of heartbeat (d)Image signal encoded by Hilbert curve")

- Dataset: PTB; Evaluation Metrics: k-fold cross validation.

- CDD can be used as a general classification module in many tasks. In the ablation experiment, the same architecture used CDD rather than CNN receives the better performance. However, Hilbert is discontinusous and the high-frequency signal could lost slightly after fixed-length sampling which affects the result little since the high-frequency signals are almost noise.

## 2023

### [11_A Computational Model of Working Memory Based on Spike-Timing-Dependent Plasticity](https://www.frontiersin.org/articles/10.3389/fncom.2021.630999/full)

- This paper proposes **a working memory model based on Spike-Timing-Dependent Plasticity(STDP)** which adopts temporal patterns of action potentials to represent information. Therefore, this model can flexibly work in persistent and silent states. This research is useful because it provides evidence that both persistent and non-persistent mechanisms exist in the brain.

### [11_A hue preserving uniform illumination image enhancement via triangle similarity criterion in HSI color space](https://link.springer.com/10.1007/s00371-022-02761-2)

- This paper proposes a hue preserving uniform illumination image enhancement via **triangle similarity criterion in hue-saturation-intensity (HSI) color space**. This enhancement aims at restoring the color of images under low illumination. The enhancement bases on two aspects: **intensity (I) and saturation (S)**. The reason is that the hue (H) is independent from I and S. The HSI color model is shown as below.

![HSI](/images/DailyPaper/01/8.png "HSI Color Model")

- The intensity enhancement process is shown below.  
$I_n = I_0 (1+\alpha), I_0 < 0.5; I_0 (1+0.5\alpha), I_0 \ge 0.5$

![Intensity Enhancement](/images/DailyPaper/01/9.png "Intensity Enhancement")

- The intensity enhancement process is shown below.  
$S_n = \frac{S_0I_0}{I_n}$

![Intensity Enhancement](/images/DailyPaper/01/10.png "Intensity Enhancement")

- Some useful evaluation metrics:  
Contrast: $C_{gain} = C_j-C_i$  
Mean contrast of an image with size M * N: $C = \frac{1}{MN} \sum_{y=1}^N \sum_{x=1}^M C(x, y)$  
Average Absolute Mean Brightness Error (AAMBE) = $\frac{1}{N}|E_0 - E_n|$  

### [11_American Sign Language Recognition for Alphabets Using Mediapipe and LSTM](https://linkinghub.elsevier.com/retrieve/pii/S1877050922021378)

- MediaPipe is a useful gesture recognition model, it can be used in many application sceneries, like [the AI pose estimation](https://www.youtube.com/watch?v=06TE_U21FK4). **MediaPipe, The K Nearest Neighbour Algorithm and Long Short-Term Memory (LSTM)** is used to American Sign Language (ASL) alphabets recognition in Human-Computer Interface (HCI). LSTM architecture consists three steps: **the forget gate, input gate and output gate**. The structure is shown below.

![LSTM](/images/DailyPaper/01/11.png "LSTM Structure")

### [12_Efficient convex region-based segmentation for noising and inhomogeneous patterns](https://www.aimsciences.org//article/doi/10.3934/ipi.2022074)

- The contour methods can be classified into region-based and edge-based models. The former method uses the image statistical information, the latter method uses the image gradient information. This paper proposes **the new convex region based segmentation framework**. The proposed method is to solve the problem of the use of region-based active contour method, the lack of robustness, and the inability to handle convex images at local minima.
- 

### [12_One-step and Two-step Classification for Abusive Language Detection on Twitter](http://aclweb.org/anthology/W17-3006)

### [12_Spectrum and Style Transformation Framework for Omni-Domain COVID-19 Diagnosis](https://ieeexplore.ieee.org/document/9954228/)

### [13_Domain Generalization via Model-Agnostic Learning of Semantic Features](https://proceedings.neurips.cc/paper/2019/file/2974788b53f73e7950e8aa49f3a306db-Paper.pdf)

### [13_Network Binarization via Contrastive Learning](https://link.springer.com/10.1007/978-3-031-20083-0_35)

### [13_Relational Graph Learning on Visual and Kinematics Embeddings for Accurate Gesture Recognition in Robotic Surgery](https://ieeexplore.ieee.org/document/9561028/)




```python
# -*- coding:UTF-8 -*-
import numpy as np
import torch
from torch import nn
import matplotlib.pyplot as plt
    # ----------------- plot -------------------
    plt.show()

```
