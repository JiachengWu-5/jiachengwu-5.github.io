---
layout: post
title: Daily Paper (2022.12.30 - 2023.1.3)
categories: [Daily Paper]
description: Some new papers
keywords: FineGPR-C, VTBR, Transformer-CNN, Encoder-Decoder, U-Net, CDD, ECG signal, STDP, Hue, LSTM, MediaPipe, ACF, HybridCNN, Twitter, Generalization, GAN, CMIM, BNN, MRG-Net, Robotic Surgery. 
---

At the beginning of the daily paper, the papers are selected from the *Researcher* app.


## 2022

### [1230_Rethinking Person Re-Identification via Semantic-Based Pretraining](https://arxiv.org/pdf/2110.05074.pdf)

- The pretraining in the ImageNet may not be the wonderful solution for the re-identification task because of the intrinsic domain gap. This paper constructed **a FineGPR-C caption dataset** to improve the semantic pretraining task for Re-ID. Besides, the **VirTex Based Re-ID pretraining approach named VTBR** is proposed. This method effectively improves the performance of supervised/unsupervised pretraining on ImageNet in some images. The reason may be that the pictures have some occlusion and multiple persons in the queries. The better performance reveals that **the semantic pretraining method can capture global context information and more discriminative parts.**
- The FineGPR-C caption dataset is generated using a dynamic caption-generating strategy. Some examples of the dataset are shown below. Moreover, the **Refined Selecting (RS) strategy** arose to decrease the redundancy among the different attributes in FineGPR-C. (RS improves performance by about 1%-5% in the comparison tests.)

![FineGPR-C](/images/DailyPaper/01/1.png "FineGPR-C")

- VTBR adapted ResNet-50 and semantic backbone transformer in the framework. The details of VTBR are shown below. The visualization of the VTBR method and other methods are shown below. It is clearly shown that the semantic information participates in the Re-ID task.
  
![VTBR](/images/DailyPaper/01/2.png "VTBR")

![Visualization](/images/DailyPaper/01/3.png "(a)Original images (b)CNN-based pretraining method on ImageNet (c)Semantic-based VTBR method on FineGPR-C caption dataset Visualization of Attention Map")


### [1231_Dual encoder network with transformer-CNN for multi-organ segmentation](https://link-springer-com.lib.ezproxy.hkust.edu.hk/article/10.1007/s11517-022-02723-9)

- This paper proposes **a dual encoder network with transformer-CNN for multi-organ segmentation**. This network is the decoder-encoder U-net architecture. CNN and transformer encoder are combined to extract the information from images. The combination is efficient, and the fusion module can suppress the overfitting problem.
- The architecture of the method is shown below. **ResNet50** is the backbone of CNN encoder, and **swin-transformer** is the backbone of the transformer encoder. Spatial and channel attention are considered in the swin-transformer so that more details can be obtained in the fusion modules. Information loss problem could be alleviated. Besides, this method could be applied to other diseases. The visualization of test results on the ACDC dataset is shown below.
  
![Architecture](/images/DailyPaper/01/4.png "The Architecture of the Method")

![Visualization](/images/DailyPaper/01/5.png "Visualization of Test Results on the ACDC Dataset")

### [1231_Application of Convolutional Dendrite Net for Detection of Myocardial Infarction Using ECG Signals](https://ieeexplore.ieee.org/document/9954400/) 

- This paper proposes **CDD (Convolutional Dendrite Net)**, based on the improved DD, to recognize the ECG signals. The structure of CDD is shown below. The primary purpose is to improve the accuracy of Myocardial Infarction (MI) detection. Besides, the Hilbert curve is used to encode ECG signals belonging to the 1-D tensor into image signals. Hilbert curve is regarded as a surjection from (0, 1) to region (0, 1) Ã— (0, 1). The ECG signal and the signal encoded by the Hilbert curve are shown below.

![CDD Net](/images/DailyPaper/01/6.jpeg "The CDD Network Structure")

![Visualization of Signal](/images/DailyPaper/01/7.jpeg "(a) Original ECG signal (b)ECG signal after artifact removal (c)ECG signal of heartbeat (d)Image signal encoded by Hilbert curve")

- Dataset: PTB; Evaluation Metrics: k-fold cross validation.

- CDD can be used as a general classification module in many tasks. In the ablation experiment, the same architecture used CDD rather than CNN received better performance. However, Hilbert is discontinuous, and the high-frequency signal could be lost slightly after fixed-length sampling, which affects the result little since the high-frequency signals are almost the noise.

## 2023

### [11_A Computational Model of Working Memory Based on Spike-Timing-Dependent Plasticity](https://www.frontiersin.org/articles/10.3389/fncom.2021.630999/full)

- This paper proposes **a working memory model based on Spike-Timing-Dependent Plasticity(STDP)**, which adopts temporal patterns of action potentials to represent information. Therefore, this model can flexibly work in persistent and silent states. This research is helpful because it provides evidence that both persistent and non-persistent mechanisms exist in the brain.

### [11_A hue preserving uniform illumination image enhancement via triangle similarity criterion in HSI color space](https://link.springer.com/10.1007/s00371-022-02761-2)

- This paper proposes a hue-preserving uniform illumination image enhancement via **triangle similarity criterion in hue-saturation-intensity (HSI) color space**. This enhancement aims at restoring the color of images under low illumination. The enhancement is based on two aspects: **intensity (I) and saturation (S)**. The reason is that the hue (H) is independent of I and S. The HSI color model is shown below.

![HSI](/images/DailyPaper/01/8.png "HSI Color Model")

- The intensity enhancement process is shown below.  
$I_n = I_0 (1+\alpha), I_0 < 0.5; I_0 (1+0.5\alpha), I_0 \ge 0.5$

![Intensity Enhancement](/images/DailyPaper/01/9.png "Intensity Enhancement")

- The saturation enhancement process is shown below.  
$S_n = \frac{S_0I_0}{I_n}$

![saturation Enhancement](/images/DailyPaper/01/10.png "Saturation Enhancement")

- Some useful evaluation metrics:  
Contrast: $C_{gain} = C_j-C_i$  
Mean contrast of an image with size M * N: $C = \frac{1}{MN} \sum_{y=1}^N \sum_{x=1}^M C(x, y)$  
Average Absolute Mean Brightness Error (AAMBE) = $\frac{1}{N}|E_0 - E_n|$  

### [11_American Sign Language Recognition for Alphabets Using Mediapipe and LSTM](https://linkinghub.elsevier.com/retrieve/pii/S1877050922021378)

- MediaPipe is a valuable gesture recognition model. It can be used in many application sceneries, like [the AI pose estimation](https://www.youtube.com/watch?v=06TE_U21FK4). **MediaPipe, The K Nearest Neighbour Algorithm and Long Short-Term Memory (LSTM)** is used for American Sign Language (ASL) alphabets recognition in Human-Computer Interface (HCI). LSTM architecture consists of three steps: **the forget gate, input gate, and output gate**. The structure is shown below.

![LSTM](/images/DailyPaper/01/11.png "LSTM Structure")

### [12_Efficient convex region-based segmentation for noising and inhomogeneous patterns](https://www.aimsciences.org//article/doi/10.3934/ipi.2022074)

- The contour methods can be classified into region-based and edge-based models. The former method uses statistical image information. The latter method uses image gradient information. This paper proposes **the new convex region-based segmentation framework**. The proposed method is to solve the problem of the region-based active contour method, the lack of robustness, and the inability to handle convex images at local minima.
- Average Convolution local Factor (ACF) is included to balance the intensity difference between neighboring pixels and intensity mean on the local interior and exterior regions
- This proposed method could be applied in **medical image segmentation** because the tested dataset is like the medical image dataset from my perspective.

### [12_One-step and Two-step Classification for Abusive Language Detection on Twitter](http://aclweb.org/anthology/W17-3006)

- This paper proposed an automatic abusive language detection method based on Twitter. **HybridCNN with Two-step classifying** is adopted to detect the various kinds of sexism and racism abusive language. This paper selects HybridCNN because the presentation form of abusive language could be characters, words, or both. The architecture of HybridCNN is shown below.

![HybridCNN](/images/DailyPaper/01/12.jpeg "Architecture of HybridCNN")

### [12_Spectrum and Style Transformation Framework for Omni-Domain COVID-19 Diagnosis](https://ieeexplore.ieee.org/document/9954228/)

- This paper proposes a plug-and-play module to improve the diagnosis performance of COVID-19 for in-domain and out-of-domain data. The data is mainly based on computed tomography (CT). The CT images collected from different devices and places are different, which could affect the final diagnosis performance. The solution proposed in this paper is that **(1) A spectrum transform module is applied to remove the high-frequency information. (2) A cross-domain stylization module is used to transfer the style features to improve the generalization capability of the deep neural network.** In the ablation study, the results show that the spectrum transform module improves in-domain performance, and the stylization module improves the performance of out-of-domain data.
  
- In the training part, generate styled data to train the GAN and obtain the best hyperparameter and network. The architecture of the proposed spectrum and style transformation framework is shown below.

![Proposal Spectrum and Style Transformation Framework](/images/DailyPaper/01/13.jpeg "Proposal Spectrum and Style Transformation Framework")

- There exists the data imbalance issue, which contributes to the bad performance of specific domains. Besides, the branch is dependent on the domain characteristics. A better adaptive strategy could solve the imbalance issue in the future.

### [13_Domain Generalization via Model-Agnostic Learning of Semantic Features](https://proceedings.neurips.cc/paper/2019/file/2974788b53f73e7950e8aa49f3a306db-Paper.pdf)

- The primary goal of this paper is similar to the paper above: To solve the problem that test data can differ significantly in the data distribution since data is collected from different equipment and environments. This paper proposes **a model-agnostic learning paradigm**. *Domain generalization* is a problem that needs to be handled.

- During the training process, domain D is randomly split into meta-train $D_tr$ and meta-test $D_te$ domains. In the following, minimizing *Kullback-Leibler divergence* between these two domains is used to align the class confusion matrix. Besides, the proposed **$L_{local}$, $L_{global}$, Contrastive Loss, and Triplet Loss** are generally orthogonal to other algorithms. The generalization capability is excellent.


### [13_Network Binarization via Contrastive Learning](https://link.springer.com/10.1007/978-3-031-20083-0_35)

- This paper builds a method called **Contrastive Learning for Mutual Information Maximization-Binary Neural Networks(CMIM-BNN)**, which maximizes the mutual information (MI). MI is the metric that measures the information shared between binary and FP activations. CMIN could learn representative binary activations, so the pull-and-pull scheme improves BNN in contrastive learning. CMIM-BNN framework is shown below. CMIM is better than several SOTA binarization methods.

![CMIN-BNN](/images/DailyPaper/01/14.jpeg "CMIN-BNN Framework")

### [13_Relational Graph Learning on Visual and Kinematics Embeddings for Accurate Gesture Recognition in Robotic Surgery](https://ieeexplore.ieee.org/document/9561028/)

- This paper proposes an online approach of **Multimodal Relational Graph Network (MRG-Net)** for robotic surgery. This network combines kinematics and visual information via extracting embeddings from video and kinematics sequences with **temporal convolutional networks and LSTM units**. This network is evaluated in the JIGSAWS dataset and achieves the SOTA performance. Also the generalization capability of this network is demonstrated in the in-house dataset. The general framework of this network is shown below.

![MRG-Net](/images/DailyPaper/01/15.png "MRG-Net")

- The whole network consists of three parts. The first part is **the visual and kinematic information extraction modules**. *ResNet-18* is the CNN backbone of the visual module. *TCN and LSTM in parallel* are responsible for the kinematic information by averaging $k_t^{tcn}$ and $k_t^{lstm}$. Secondly, *the fusion model* is adopted to fuse the above extracted high-level embeddings of each time step. The final part is interacting with the multimodal information in latent space to capture collective knowledge. This part contains three types of relationship: *Vision-to-Motion, Motion-to-Vision, and in-between-Motions*. After finishing all mentioned above, the *Softmax* function is applied to obtain the classification prediction.

- Also, the paper raises the problem of data variance and domain gap because of the different data-source. From my perspective, **generalization** is a significant problem for medical image diagnosis, especially under expensive and rare data conditions.

After reading these inspiring and exciting papers, I realized that I need to learn more about the classical computer vision models to find out the specific network's advantages and disadvantages.
